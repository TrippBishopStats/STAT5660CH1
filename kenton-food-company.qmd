---
title: "Kenton Food Company"
format: html
editor: source
execute: 
  warning: false
  messages: false
---

```{r initial setup}
library(tidyverse)

# a simple helper function
matrix_trace <- function(mtx) {
  return(sum(diag(mtx)))
}

df_cereal <- read_csv("KentonFoodData.csv") |> 
  mutate(
    store = as_factor(store),
    design = as_factor(design)
  )

head(df_cereal)
```

Now, to confirm that we have the correct data, create a matrix display it with
labels to make it easier to understand.

```{r}
store_names <- levels(df_cereal$store)
design_names <- levels(df_cereal$design)

cols <- store_names |> length()
rows <- design_names |> length()

matrix(df_cereal$sales, ncol=cols, nrow=rows, byrow=TRUE,
       dimnames=list(design_names, store_names))
```

Fit a linear model, look at the coefficients, and look at the omnibus test that
the means are equal.

```{r}
fit <- lm(sales~design, data=df_cereal)
cbind(summary(fit)$coefficients, confint(fit))
anova(fit)
```

Now replicate the output of `lm()` and `anova()` with matrix operations "by
hand".

Start by organising the raw data.

```{r}
df_cereal <- na.omit(df_cereal) # have to drop missing values or it will choke
n <- nrow(df_cereal)

X <- model.matrix(~1+design, data=df_cereal)
y <- matrix(df_cereal$sales, ncol=1)
```

Now that we have defined the basic data, we need to generate some of the
derivative matrices that will be used repeatedly.

```{r}
X_t <- t(X)
y_t <- t(y)
scaling <- solve(X_t%*%X) # (X_t%*%X)^)(-1)
H <- X%*%scaling%*%X_t
I <- diag(rep(1,times=n))
J <- matrix(rep(1, times=n^2), ncol=n)
```

Now, we can make our parameter estimates, compute the mean squared error and
mean square residuals to get an F statistic for the omnibus test that the means
are all equal (ie that there is just one global mean and the design coefficients
are all zero).

The rank of the matrix of the quadratic form tells us the degrees of freedom
associated with the statistic, so it's an easy way to determine what we need
in the denominator.

```{r}
df_reduced <- matrix_trace(I-H)
df_full <- matrix_trace(H-1/n*J)
MSE <- (y_t%*%(I-H)%*%y)/df_reduced
MSR <- y_t%*%(H - 1/n*J)%*%y/df_full

F_stat <- MSR/MSE
pval <- pf(F_stat, df_full, df_reduced, lower.tail=FALSE) |> round(digits=7)
```
For this test, $F(`r df_full`,`r df_reduced`)=`r round(F_stat,3)`
$ with $p=`r pval`$.

Now, estimate the population parameters and compute 95% confidence intervals.

```{r}
B <- scaling%*%X_t%*%y
S_b <- as.numeric(MSE)*scaling
t_crit <- qt(0.975, df=15)
std_errs <- sqrt(diag(S_b))

parameter_estimates <- cbind(
  Estimate = B,
  std_err = std_errs,
  `2.5%` = B - t_crit*std_errs,
  `97.5%` = B + t_crit*std_errs
)

colnames(parameter_estimates) <- c("Estimate","Std Errs", "2.5%","97.5%")

parameter_estimates
```
## Using the new tools

```{r}
library(kableExtra)
source("my_lm.R")

my.fit <- my_lm(as.vector(y), X)
my.fit$estimates |> kable()
```

### Formal hypothesis test of $\beta_1$

**Step 1** - State the formal hypothesis  

$$
\begin{aligned}
H_0 &: \beta_1 = 0\\
H_a &: \beta_1 \neq 0
\end{aligned}
$$
with $\alpha=0.05$.

**Step 2** - Determine test statistic and critical value  

```{r}
df <- my.fit$df[2]
t_2 <- my.fit$estimates[2,3] |> round(digits=3)
t_crit <- qt(0.975, df=df) |> round(digits=3)
```
We have already calculated the test statistic for $\hat{\beta_1}$ and it is
displayed in the table above. With this data, $t_{`r df`} = `r t_2`$. The
critical value for this test is $t^*_{`r df`}=`r t_crit`$.

**Step 3** - Decision  
With $|t^*_{`r df`}|=`r t_crit` > |t_{`r df`}|=`r t_2`$, we fail to reject 
$H_0: \beta_1 = 0$ at the $\alpha=0.05$ significance level.

**Step 4** - Conclusion  
*Statistical* - There is not sufficient evidence to support the claim that 
$\beta_1 \neq 0$ with 95% confidence.

*Practical* - There may not be a linear relationship between `sales` and package
design 2, with 95% confidence. In other words, it does not look like design 2
impacts the sales of cereal.


```{r}
my.fit$estimates

lwr <- my.fit$estimates[2,5]
upr <- my.fit$estimates[2,6]

lwr
upr
```

```{r}




```

